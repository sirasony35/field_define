import os
import torch
import numpy as np
import rasterio
from PIL import Image
from transformers import AutoImageProcessor, AutoModelForSemanticSegmentation
import cv2
import folium
from folium.features import GeoJson
from rasterio.warp import transform
from huggingface_hub import snapshot_download
import traceback

# ==============================================================================
# 1. ì„¤ì •: ìš°ë¦¬ê°€ ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰í–ˆë˜ NVIDIA ëª¨ë¸ì„ ìµœì¢… ì‚¬ìš©í•©ë‹ˆë‹¤.
# ==============================================================================
# â­ï¸ ìµœì¢… ëª¨ë¸: NVIDIA SegFormer-B1 (ADE20k ë°ì´í„°ì…‹ìœ¼ë¡œ í•™ìŠµë¨)
MODEL_NAME = "nvidia/segformer-b1-finetuned-ade-512-512"

# â­ï¸â­ï¸â­ï¸ ê°€ì¥ ì¤‘ìš”í•œ ìˆ˜ì • â­ï¸â­ï¸â­ï¸
# ì´ì „ ì§„ë‹¨ ê²°ê³¼, ëª¨ë¸ì´ ê²½ì‘ì§€ë¥¼ 'ë‚˜ë¬´(tree)'ë¡œ íŒë‹¨í–ˆìœ¼ë¯€ë¡œ,
# ì°¾ê³ ì í•˜ëŠ” í´ë˜ìŠ¤ IDë¥¼ 16('field')ì´ ì•„ë‹Œ 4('tree')ë¡œ ë³€ê²½í•©ë‹ˆë‹¤.
CROPLAND_CLASS_ID = 4

# ì‚¬ìš©ì íŒŒì¼ ì„¤ì •
TIFF_FILE_PATH = 'data/2025-09-10, daedong_hs.data.tif'
OUTPUT_HTML_PATH = 'classification_map_final.html'
MODEL_SAVE_DIRECTORY = "model/" # ê¸°ì¡´ì— ë‹¤ìš´ë¡œë“œí•œ NVIDIA ëª¨ë¸ í´ë”
MIN_AREA_THRESHOLD = 150

# ==============================================================================
# 2. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥ (ì´ë¯¸ ë‹¤ìš´ë¡œë“œ ë˜ì–´ìˆìœ¼ë¯€ë¡œ ê±´ë„ˆë›°ê²Œ ë©ë‹ˆë‹¤)
# ==============================================================================
def download_model_if_needed(repo_id, save_dir):
    if not os.path.exists(os.path.join(save_dir, "config.json")):
        print(f"'{repo_id}' ëª¨ë¸ì´ ë¡œì»¬ì— ì—†ìŠµë‹ˆë‹¤. ë‹¤ìš´ë¡œë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
        try:
            snapshot_download(repo_id=repo_id, local_dir=save_dir, local_dir_use_symlinks=False, resume_download=True)
            print("ğŸ‰ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì„±ê³µ!")
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜: ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨. {e}"); return False
    else:
        print(f"'{repo_id}' ëª¨ë¸ì´ ë¡œì»¬ì— ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. ë‹¤ìš´ë¡œë“œë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
    return True

# ==============================================================================
# ë©”ì¸ ë¶„ì„ ë¡œì§ ì‹œì‘
# ==============================================================================
print("ğŸ¤– [ìµœì¢… ë²„ì „] ê²½ì‘ì§€ ìë™ ë¶„ë¥˜ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")

# ë‹¨ê³„ 1: ëª¨ë¸ í™•ì¸
if not download_model_if_needed(MODEL_NAME, MODEL_SAVE_DIRECTORY):
    exit(1)

# ë‹¨ê³„ 2: ëª¨ë¸ ë° ì´ë¯¸ì§€ í”„ë¡œì„¸ì„œ ë¶ˆëŸ¬ì˜¤ê¸°
print("\n>> ë‹¨ê³„ 1: ë¡œì»¬ í´ë”ì—ì„œ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤...")
try:
    image_processor = AutoImageProcessor.from_pretrained(MODEL_SAVE_DIRECTORY)
    model = AutoModelForSemanticSegmentation.from_pretrained(MODEL_SAVE_DIRECTORY)
    print("   ...ëª¨ë¸ ë¡œë”© ì„±ê³µ!")
except Exception:
    print(f"   âŒ ì˜¤ë¥˜: ëª¨ë¸ ë¡œë”© ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."); traceback.print_exc(); exit(1)

# ë‹¨ê³„ 3: ìœ„ì„± ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸° ë° ì „ì²˜ë¦¬
print(f"\n>> ë‹¨ê³„ 2: ìœ„ì„± ì´ë¯¸ì§€ '{TIFF_FILE_PATH}'ë¥¼ ë¶ˆëŸ¬ì˜¤ê³  ì „ì²˜ë¦¬í•©ë‹ˆë‹¤...")
try:
    with rasterio.open(TIFF_FILE_PATH) as src:
        bands = src.read([3, 2, 1])
        nodata_val = src.nodatavals[0]
        stretched_bands = []
        for band_data in bands:
            if nodata_val is not None:
                masked_data = np.ma.masked_equal(band_data, nodata_val)
                p2, p98 = np.percentile(masked_data.compressed(), (2, 98))
            else:
                p2, p98 = np.percentile(band_data, (2, 98))
            if p98 - p2 == 0: stretched = np.zeros_like(band_data, dtype=np.uint8)
            else:
                stretched = np.clip((band_data - p2) / (p98 - p2), 0, 1)
                stretched = (stretched * 255).astype(np.uint8)
            stretched_bands.append(stretched)
        rgb_image_np = np.dstack(stretched_bands)
        image = Image.fromarray(rgb_image_np)
        src_crs = src.crs
        src_transform = src.transform
        src_bounds = src.bounds
        print("   ...ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì„±ê³µ!")
except Exception:
    print(f"   âŒ ì˜¤ë¥˜: ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."); traceback.print_exc(); exit(1)

# ë‹¨ê³„ 4: ëª¨ë¸ ì¶”ë¡ ìœ¼ë¡œ ê²½ì‘ì§€ ì˜ˆì¸¡
print("\n>> ë‹¨ê³„ 3: ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ê²½ì‘ì§€ ì˜ì—­ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤...")
inputs = image_processor(images=image, return_tensors="pt")
with torch.no_grad():
    outputs = model(**inputs)
logits = outputs.logits.cpu()
upsampled_logits = torch.nn.functional.interpolate(logits, size=image.size[::-1], mode="bilinear", align_corners=False)
pred_seg = upsampled_logits.argmax(dim=1)[0].numpy().astype(np.uint8)
print("   ...ê²½ì‘ì§€ ì˜ˆì¸¡ ì™„ë£Œ!")

# ë‹¨ê³„ 5: ê²°ê³¼ í›„ì²˜ë¦¬ ë° ì§€ë„ ìƒì„±
print("\n>> ë‹¨ê³„ 4: ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³  HTML ì§€ë„ë¡œ ë§Œë“­ë‹ˆë‹¤...")
# â­ï¸â­ï¸â­ï¸ ë°”ë¡œ ì´ ë¶€ë¶„ì—ì„œ ID 4('tree')ì— í•´ë‹¹í•˜ëŠ” ì˜ì—­ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤! â­ï¸â­ï¸â­ï¸
cropland_mask = np.where(pred_seg == CROPLAND_CLASS_ID, 255, 0).astype(np.uint8)
num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(cropland_mask, connectivity=8)
center_lon = (src_bounds.left + src_bounds.right) / 2
center_lat = (src_bounds.top + src_bounds.bottom) / 2
center_coords_web = transform(src_crs, {'init': 'epsg:4326'}, [center_lon], [center_lat])
m = folium.Map(location=[center_coords_web[1][0], center_coords_web[0][0]], zoom_start=15, tiles='https://mt1.google.com/vt/lyrs=s&x={x}&y={y}&z={z}', attr='Google Satellite')
final_field_count = 0
geojson_features = []
for i in range(1, num_labels):
    if stats[i, cv2.CC_STAT_AREA] >= MIN_AREA_THRESHOLD:
        final_field_count += 1
        component = (labels == i).astype(np.uint8)
        contours, _ = cv2.findContours(component, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        for contour in contours:
            coords = []
            for point in contour:
                lon, lat = src_transform * (point[0][0], point[0][1])
                lon_web, lat_web = transform(src_crs, {'init': 'epsg:4326'}, [lon], [lat])
                coords.append((lon_web[0], lat_web[0]))
            feature = {"type": "Feature", "geometry": {"type": "Polygon", "coordinates": [coords]}, "properties": {"field_id": final_field_count}}
            geojson_features.append(feature)
if geojson_features:
    geojson_layer = GeoJson({"type": "FeatureCollection", "features": geojson_features}, style_function=lambda x: {'fillColor': '#4CAF50', 'color': '#2E7D32', 'weight': 2, 'fillOpacity': 0.6}, tooltip=folium.GeoJsonTooltip(fields=['field_id'], aliases=['ê²½ì‘ì§€ ë²ˆí˜¸:'])).add_to(m)
    m.fit_bounds(geojson_layer.get_bounds())
m.save(OUTPUT_HTML_PATH)
print("   ...ì§€ë„ ìƒì„± ì™„ë£Œ!")
print("\n" + "="*50)
print(f"ğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ! ì´ {final_field_count}ê°œì˜ ê²½ì‘ì§€ë¥¼ ì‹ë³„í•˜ì—¬ '{OUTPUT_HTML_PATH}' íŒŒì¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
print("ìƒì„±ëœ HTML íŒŒì¼ì„ ì›¹ ë¸Œë¼ìš°ì €ì—ì„œ ì—´ì–´ ê²°ê³¼ë¥¼ í™•ì¸í•´ë³´ì„¸ìš”.")
print("="*50)